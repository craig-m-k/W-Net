{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wnet for unsupervised segmentation\n",
    "\n",
    "https://arxiv.org/abs/1711.08506\n",
    "\n",
    "Based on these repos:\n",
    "\n",
    "* https://github.com/lwchen6309/unsupervised-image-segmentation-by-WNet-with-NormalizedCut\n",
    "* https://github.com/zwenaing/unsupervised-image-segmentation \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow < 2.0\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import wnet\n",
    "from input_data import DataReader\n",
    "from soft_ncut import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print iterations progress\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to the directory containing the video frames.\n",
    "train_vid_dir = ''\n",
    "\n",
    "# network parameters\n",
    "n_batch = 1\n",
    "learning_rate = 0.003\n",
    "num_steps = 1000//n_batch\n",
    "num_epochs = 50\n",
    "display_step = 1000//n_batch\n",
    "num_classes =  20\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "autoencoder = wnet.Wnet(num_classes=all_params['num_classes'])\n",
    "data_reader = DataReader(train_vid_dir, batch_size=n_batch)\n",
    "\n",
    "image = tf.placeholder(tf.float32, [None, 224, 224, 3], name=\"image\")\n",
    "neighbor_indices = tf.placeholder(tf.int64, name=\"neighbor_indices\")\n",
    "neighbor_vals = tf.placeholder(tf.float32, name=\"neighbor_vals\")\n",
    "neighbor_shape = tf.placeholder(tf.int64, name=\"neighbor_shape\")\n",
    "\n",
    "with tf.name_scope(\"Encoding\"):\n",
    "    encoded_image = autoencoder.encode(image)    \n",
    "    argmax = tf.argmax(encoded_image, axis=3)\n",
    "    scaled = tf.multiply(argmax, 256//num_classes)\n",
    "    reshaped = tf.reshape(scaled, [-1, 224, 224, 1])\n",
    "    seg = tf.cast(reshaped, tf.uint8)\n",
    "    \n",
    "with tf.name_scope(\"Decoding\"):\n",
    "    decoded_image = autoencoder.decode(encoded_image)\n",
    "\n",
    "with tf.name_scope(\"Loss\"):\n",
    "    # Loss has two parts: reconstruction loss and \"soft n-cut\" loss\n",
    "    y_pred = tf.reshape(decoded_image, [-1, 150528])\n",
    "    y_true = tf.reshape(image, [-1, 150528])\n",
    "    reconstruction_loss = tf.reduce_mean(tf.pow(y_pred - y_true, 2))\n",
    "    \n",
    "    neighbor_filter = (neighbor_indices, neighbor_vals, neighbor_shape)\n",
    "    _image_weights = brightness_weight(image, neighbor_filter, sigma_I = all_params['sigma_I'])\n",
    "    image_weights = convert_to_batchTensor(*_image_weights)\n",
    "    soft_ncut_loss = soft_ncut(image, encoded_image, image_weights)[0]\n",
    "    loss = reconstruction_loss + soft_ncut_loss\n",
    "    \n",
    "with tf.name_scope(\"Optimization\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss=loss)\n",
    "\n",
    "orig_img_summary = tf.summary.image('original', image)\n",
    "dec_img_summary = tf.summary.image('decoded', decoded_image)\n",
    "seg_img_summary = tf.summary.image('segmentation', seg)\n",
    "tf.summary.scalar(\"Loss\", loss)\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(filename=\"ckpt\")\n",
    "\n",
    "iterator = data_reader.input_data(num_images=all_params['train_size'])\n",
    "flist, next_items = iterator.get_next()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(iterator.initializer)\n",
    "    var = np.sum([np.prod(v.shape) for v in tf.trainable_variables()])\n",
    "    print(\"Trainable vars: \", var)\n",
    "    train_writer = tf.summary.FileWriter(logdir, graph=tf.get_default_graph())\n",
    "\n",
    "    if exists(logdir):\n",
    "        if ckpt is not None:\n",
    "            saver.restore(sess, ckpt)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        i = 0\n",
    "        losses = np.zeros((num_steps+1))\n",
    "        times = np.zeros((num_steps+1))\n",
    "        printProgressBar(0, num_steps+1, prefix = 'Epoch {}'.format(str(epoch)), suffix = '', length = 50)\n",
    "        while True:\n",
    "            try:\n",
    "                assert i <= num_steps\n",
    "                stime = timeit.default_timer()\n",
    "                batch_x =  sess.run(next_items)\n",
    "                image_shape = image.get_shape().as_list()[1:3]\n",
    "                \n",
    "                gauss_indices, gauss_vals = gaussian_neighbor(image_shape, \n",
    "                                                              sigma_X=all_params['sigma_X'],\n",
    "                                                              r=all_params['r'])\n",
    "                weight_shapes = np.prod(image_shape).astype(np.int64)\n",
    "                \n",
    "                feed_dict = {image: batch_x,\n",
    "                            neighbor_indices : gauss_indices,\n",
    "                            neighbor_shape : [weight_shapes, weight_shapes],\n",
    "                            neighbor_vals : gauss_vals}\n",
    "                if i != 0 and i % display_step == 0:\n",
    "                    loss_, _, summary = sess.run([loss, train_op, merged_summary], feed_dict=feed_dict)\n",
    "                    losses[i] = loss_\n",
    "                    train_writer.add_summary(summary)\n",
    "                    saver.save(sess, os.path.join(logdir, 'ckpt'), global_step=global_step + i)\n",
    "                else:\n",
    "                    loss_, _ = sess.run([loss, train_op], feed_dict=feed_dict)\n",
    "                    losses[i] = loss_\n",
    "                etime = timeit.default_timer()\n",
    "                times[i] = etime-stime\n",
    "                printProgressBar(i+1, num_steps+1, prefix = 'Epoch {}'.format(str(epoch)), suffix = 'Loss: {:.2f}'.format(loss_), length = 50)\n",
    "                i += 1\n",
    "            except (AssertionError, tf.errors.OutOfRangeError):\n",
    "                print(\"Epoch: {} Avg Loss: {:.2f} Avg time/batch: {:.2f} s\".format(str(epoch), np.average(losses), np.average(times)))\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For converting class labels into RGB.\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import to_rgb\n",
    "cl = params['num_classes']\n",
    "cmap = plt.get_cmap('viridis')\n",
    "seg_colors = {i : to_rgb(cmap(i*1/cl)) for i in range(num_classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    "\n",
    "# Change this to the full path of the checkpoint metagraph.\n",
    "ckpt_meta = ''\n",
    "\n",
    "# Change this to the full path of the checkpoint file\n",
    "ckpt_file = ''\n",
    "\n",
    "def ssoftmax(z):\n",
    "    ez = np.exp(z - np.max(z))\n",
    "    return ez / ez.sum(axis=2, keepdims=True)\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    i = 0\n",
    "    tf.train.import_meta_graph(ckpt_meta)\n",
    "    tf.train.Saver().restore(sess, ckpt_file)\n",
    "    softmax = 'Encoding/rectangle9/softmax/Softmax:0'\n",
    "    files = sorted(glob.glob(os.path.join(test_vid_dir, '*.jpg')))\n",
    "    for f in files:\n",
    "        img = cv2.imread(f)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_u = img.astype(np.uint8)\n",
    "        img_exp_f = img.reshape((-1, 224, 224, 3)).astype(np.float32)\n",
    "        img_shape = img_exp_f.shape[1:3]\n",
    "        gauss_indices, gauss_vals = gaussian_neighbor(img_shape, sigma_X = 4, r = 5)\n",
    "        weight_shapes = np.prod(img_shape).astype(np.int64)\n",
    "        feed_dict = {'image:0': img_exp_f,\n",
    "                     'neighbor_indices:0' : gauss_indices,\n",
    "                     'neighbor_shape:0' : [weight_shapes, weight_shapes],\n",
    "                     'neighbor_vals:0' : gauss_vals}\n",
    "        softmax_output = sess.run(softmax, feed_dict=feed_dict)\n",
    "        img_seg = np.argmax(softmax_output, axis=3).astype(np.uint8).squeeze()\n",
    "        img_seg_color = (np.array(np.vectorize(seg_colors.__getitem__)(img_seg)).transpose(1,2,0)*255).astype(np.uint8)\n",
    "        img_seg_color = img_seg_color.reshape((224, 224, 3))\n",
    "        img_final = cv2.cvtColor(img_seg_color, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(str(i).zfill(5) + '.png', img_final)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
